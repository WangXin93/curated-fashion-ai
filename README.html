<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>Markmap</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>

</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@5"></script><script src="https://cdn.jsdelivr.net/npm/markmap-lib@0.7.10/dist/browser/view.min.js"></script><script>((data, init, items, opts) => {
        const {
          Markmap,
          loadPlugins
        } = window.markmap;
        (init ? init(loadPlugins, items, opts) : Promise.resolve()).then(() => {
          Markmap.create('svg#mindmap', null, data);
        });
      })({"t":"heading","d":1,"v":"Curated Fashion AI","c":[{"t":"heading","d":2,"v":"1. Papers","c":[{"t":"heading","d":3,"v":"1.1 Fashion recognition","c":[{"t":"list_item","d":4,"v":"<a href=\"https://liuziwei7.github.io/projects/DeepFashion.html\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">DeepFashion: Powering Robust Clothes Recognition and Retrieval with Rich Annotations</a>"}]},{"t":"heading","d":3,"v":"1.2 Fashion Detection","c":[{"t":"list_item","d":4,"v":"<a href=\"http://openaccess.thecvf.com/content_CVPR_2019/papers/Yu_Layout-Graph_Reasoning_for_Fashion_Landmark_Detection_CVPR_2019_paper.pdf\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">Layout-Graph Reasoning for Fashion Landmark Detection</a>"},{"t":"list_item","d":4,"v":"<a href=\"http://openaccess.thecvf.com/content_ICCVW_2019/papers/CVFAD/Sidnev_DeepMark_One-Shot_Clothing_Detection_ICCVW_2019_paper.pdf\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">DeepMark: One-Shot Clothing Detection</a>"}]},{"t":"heading","d":3,"v":"1.3 Fashion Recommendation","c":[{"t":"heading","d":4,"v":"1.3.1 Pairwise Recommendation","c":[{"t":"list_item","d":5,"v":"<a href=\"http://openaccess.thecvf.com/content_CVPR_2019/papers/Cucurull_Context-Aware_Visual_Compatibility_Prediction_CVPR_2019_paper.pdf\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">Context-Aware Visual Compatibility Prediction</a>"},{"t":"list_item","d":5,"v":"<a href=\"https://rose.ntu.edu.sg/Publications/Documents/Fashion%20Analytics/Tiered%20Similarity%20Search%20for%20Fashion.pdf\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">Tiered Deep Similarity Search for Fashion</a>"},{"t":"list_item","d":5,"v":"<a href=\"https://arxiv.org/abs/1812.10021\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">TransNFCM: Translation-Based Neural Fashion Compatibility Modeling</a>"}]},{"t":"heading","d":4,"v":"1.3.2 Outfit Compatibility","c":[{"t":"list_item","d":5,"v":"<a href=\"https://arxiv.org/pdf/1905.01866.pdf\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">POG: Personalized Outfit Generation for Fashion Recommendation at Alibaba iFashion</a>"}]},{"t":"heading","d":4,"v":"1.3.3 Compatibility Interpretation","c":[{"t":"list_item","d":5,"v":"<a href=\"https://arxiv.org/abs/1907.11496\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">Outfit Compatibility Prediction and Diagnosis with Multi-Layered Comparison Network</a>"},{"t":"list_item","d":5,"v":"<a href=\"http://staff.ustc.edu.cn/~hexn/papers/sigir19-fashion.pdf\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">Interpretable Fashion Matching with Rich Attributes</a>"},{"t":"list_item","d":5,"v":"<a href=\"http://www.yongfeng.me/attach/chen-sigir2019.pdf\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">Personalized Fashion Recommendation with Visual Explanations based on Multimodal Attention Network</a>"},{"t":"list_item","d":5,"v":"<a href=\"https://arxiv.org/pdf/1905.12862v1.pdf\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">Explainable Fashion Recommendation: A Semantic Attribute Region Guided Approach</a>"}]},{"t":"heading","d":4,"v":"1.3.4 Wardrobe Creation","c":[{"t":"list_item","d":5,"v":"<a href=\"http://openaccess.thecvf.com/content_cvpr_2018/papers/Hsiao_Creating_Capsule_Wardrobes_CVPR_2018_paper.pdf\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">Creating Capsule Wardrobes from Fashion Images</a>"},{"t":"list_item","d":5,"v":"<a href=\"https://liqiangnie.github.io/paper/PersonalizedCapsuleWardrobeCreationwithGarmentandUserModeling.pdf\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">Personalized Capsule Wardrobe Creation with Garment and User Modeling</a>"}]}]},{"t":"heading","d":3,"v":"1.4 Image-based Virtual Try-on","c":[{"t":"list_item","d":4,"v":"<a href=\"http://openaccess.thecvf.com/content_cvpr_2018/papers/Han_VITON_An_Image-Based_CVPR_2018_paper.pdf\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">VITON: An Image-based Virtual Try-on Network</a>"},{"t":"list_item","d":4,"v":"<a href=\"https://xuemengsong.github.io/fp452-zhengA.pdf\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">Virtually Trying on New Clothing with Arbitrary Poses</a>"}]},{"t":"heading","d":3,"v":"1.5 Fashion Editing","c":[{"t":"list_item","d":4,"v":"<a href=\"https://arxiv.org/abs/1904.09261\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">Fashion++: Minimal Edits for Outfit Improvement</a>"},{"t":"list_item","d":4,"v":"<a href=\"https://arxiv.org/abs/1906.00884\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">Fashion Editing with Multi-scale Attention Normalization</a>"},{"t":"list_item","d":4,"v":"<a href=\"https://arxiv.org/abs/1904.07460\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">Fashion-AttGAN: Attribute-Aware Fashion Editing with Multi-Objective GAN</a>"},{"t":"list_item","d":4,"v":"<a href=\"https://arxiv.org/abs/1902.01096\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">Compatible and Diverse Fashion Image Inpainting</a>"}]},{"t":"heading","d":3,"v":"1.6 3D Garment","c":[{"t":"list_item","d":4,"v":"<a href=\"https://arxiv.org/pdf/2003.12753v1.pdf\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">Deep Fashion3D: A Dataset and Benchmark for 3D Garment Reconstruction from Single Images</a>"}]},{"t":"heading","d":3,"v":"1.7 Fit and Size Recommendation","c":[{"t":"list_item","d":4,"v":"<a href=\"http://cseweb.ucsd.edu/~jmcauley/pdfs/recsys18e.pdf\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">Decomposing Fit Semantics for Product Size Recommendation in Metric Spaces</a>"}]}]},{"t":"heading","d":2,"v":"2. Workshop","c":[{"t":"list_item","d":3,"v":"<a href=\"https://sites.google.com/view/cvcreative/home?authuser=0\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">ICCV 2019 Second Workshop on Computer Vision for Fashion, Art and Design</a>"}]},{"t":"heading","d":2,"v":"3. Datasets","c":[{"t":"thead","d":3,"v":"","c":[{"t":"th","d":4,"v":""},{"t":"th","d":4,"v":"Image"},{"t":"th","d":4,"v":"Text"},{"t":"th","d":4,"v":"Category"},{"t":"th","d":4,"v":"Attribute"},{"t":"th","d":4,"v":"Landmark"},{"t":"th","d":4,"v":"Box"},{"t":"th","d":4,"v":"Mask"},{"t":"th","d":4,"v":"Relation"},{"t":"th","d":4,"v":"Other"}]},{"t":"tbody","d":3,"v":"","c":[{"t":"tr","d":4,"v":"","c":[{"t":"td","d":5,"v":"<a href=\"https://data.vision.ee.ethz.ch/cvl/lbossard/accv12/\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">ACWS</a>"},{"t":"td","d":5,"v":":white_check_mark:"},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":":white_check_mark:"},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""}]},{"t":"tr","d":4,"v":"","c":[{"t":"td","d":5,"v":"<a href=\"https://github.com/Cysu/noisy_label\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">Clothing1M</a>"},{"t":"td","d":5,"v":":white_check_mark:"},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":":white_check_mark:"},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""}]},{"t":"tr","d":4,"v":"","c":[{"t":"td","d":5,"v":"<a href=\"http://chenlab.ece.cornell.edu/people/Andy/publications/ECCV2012_ClothingAttributes.pdf\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">DCSA</a>"},{"t":"td","d":5,"v":":white_check_mark:"},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":":white_check_mark:"},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""}]},{"t":"tr","d":4,"v":"","c":[{"t":"td","d":5,"v":"<a href=\"http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">DeepFashion</a>"},{"t":"td","d":5,"v":":white_check_mark:"},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":":white_check_mark:"},{"t":"td","d":5,"v":":white_check_mark:"},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":"street2shop"},{"t":"td","d":5,"v":""}]},{"t":"tr","d":4,"v":"","c":[{"t":"td","d":5,"v":"<a href=\"https://github.com/switchablenorms/DeepFashion2\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">DeepFashion2</a>"},{"t":"td","d":5,"v":":white_check_mark:"},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":":white_check_mark:"},{"t":"td","d":5,"v":":white_check_mark:"},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":":white_check_mark:"},{"t":"td","d":5,"v":"street2shop"},{"t":"td","d":5,"v":""}]},{"t":"tr","d":4,"v":"","c":[{"t":"td","d":5,"v":"<a href=\"https://vision.cornell.edu/se3/wp-content/uploads/2019/06/1906.05750.pdf\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">imaterialist-2018</a>"},{"t":"td","d":5,"v":":white_check_mark:"},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":":white_check_mark:"},{"t":"td","d":5,"v":":white_check_mark:"},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""}]},{"t":"tr","d":4,"v":"","c":[{"t":"td","d":5,"v":"<a href=\"https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">imaterialist-2019</a>"},{"t":"td","d":5,"v":":white_check_mark:"},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":":white_check_mark:"},{"t":"td","d":5,"v":":white_check_mark:"},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":":white_check_mark:"},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""}]},{"t":"tr","d":4,"v":"","c":[{"t":"td","d":5,"v":"<a href=\"http://tamaraberg.com/street2shop/\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">WTBI</a>"},{"t":"td","d":5,"v":":white_check_mark:"},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":""},{"t":"td","d":5,"v":"street2shop"},{"t":"td","d":5,"v":""}]}]}]},{"t":"heading","d":2,"v":"4. Company","c":[{"t":"list_item","d":3,"v":"<a href=\"https://hackernoon.com/how-we-grew-from-0-to-4-million-women-on-our-fashion-app-with-a-vertical-machine-learning-approach-f8b7fc0a89d7\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">Chicisimo</a>"},{"t":"list_item","d":3,"v":"<a href=\"https://www.infimind.com/#\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">infimind</a>"}]},{"t":"heading","d":2,"v":"Similar Repository","c":[{"t":"list_item","d":3,"v":"<a href=\"https://github.com/lzhbrian/Cool-Fashion-Papers\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">Cool Fashion Papers</a>"},{"t":"list_item","d":3,"v":"<a href=\"https://github.com/ayushidalmia/awesome-fashion-ai\" title=\"\" target=\"_blank\" rel=\"noopener noreferrer\">awesome-fashion-ai</a>"}]}]},(loadPlugins, items, opts) => loadPlugins(items, opts),["mathJax"],{"mathJax":{},"content":"# Curated Fashion AI\n\nFashion study is an interesting interdisciplinary subject between computer vision, natural language processing, recommendation system and fashion design etc. The research about fashion and artificial intelligence (AI) is rapidly evolved in this decade. This repository curates recent researches and resources about fashion and AI, hopes to help researchers who are interested in this field.\n\nThe following content is divided according to different subjects:\n\n## 1. Papers\n\n### 1.1 Fashion recognition\n\n* [DeepFashion: Powering Robust Clothes Recognition and Retrieval with Rich Annotations](https://liuziwei7.github.io/projects/DeepFashion.html)\n\n### 1.2 Fashion Detection\n\n* [Layout-Graph Reasoning for Fashion Landmark Detection](http://openaccess.thecvf.com/content_CVPR_2019/papers/Yu_Layout-Graph_Reasoning_for_Fashion_Landmark_Detection_CVPR_2019_paper.pdf)\n* [DeepMark: One-Shot Clothing Detection](http://openaccess.thecvf.com/content_ICCVW_2019/papers/CVFAD/Sidnev_DeepMark_One-Shot_Clothing_Detection_ICCVW_2019_paper.pdf)\n\n### 1.3 Fashion Recommendation\n\n#### 1.3.1 Pairwise Recommendation\n\n* [Context-Aware Visual Compatibility Prediction](http://openaccess.thecvf.com/content_CVPR_2019/papers/Cucurull_Context-Aware_Visual_Compatibility_Prediction_CVPR_2019_paper.pdf)\n* [Tiered Deep Similarity Search for Fashion](https://rose.ntu.edu.sg/Publications/Documents/Fashion%20Analytics/Tiered%20Similarity%20Search%20for%20Fashion.pdf)\n* [TransNFCM: Translation-Based Neural Fashion Compatibility Modeling](https://arxiv.org/abs/1812.10021)\n\n#### 1.3.2 Outfit Compatibility\n\n* [POG: Personalized Outfit Generation for Fashion Recommendation at Alibaba iFashion](https://arxiv.org/pdf/1905.01866.pdf)\n\n#### 1.3.3 Compatibility Interpretation\n\n* [Outfit Compatibility Prediction and Diagnosis with Multi-Layered Comparison Network](https://arxiv.org/abs/1907.11496)\n* [Interpretable Fashion Matching with Rich Attributes](http://staff.ustc.edu.cn/~hexn/papers/sigir19-fashion.pdf)\n* [Personalized Fashion Recommendation with Visual Explanations based on Multimodal Attention Network](http://www.yongfeng.me/attach/chen-sigir2019.pdf)\n* [Explainable Fashion Recommendation: A Semantic Attribute Region Guided Approach](https://arxiv.org/pdf/1905.12862v1.pdf)\n\n#### 1.3.4 Wardrobe Creation\n\n* [Creating Capsule Wardrobes from Fashion Images](http://openaccess.thecvf.com/content_cvpr_2018/papers/Hsiao_Creating_Capsule_Wardrobes_CVPR_2018_paper.pdf)\n* [Personalized Capsule Wardrobe Creation with Garment and User Modeling](https://liqiangnie.github.io/paper/PersonalizedCapsuleWardrobeCreationwithGarmentandUserModeling.pdf)\n\n### 1.4 Image-based Virtual Try-on\n\n* [VITON: An Image-based Virtual Try-on Network](http://openaccess.thecvf.com/content_cvpr_2018/papers/Han_VITON_An_Image-Based_CVPR_2018_paper.pdf)\n* [Virtually Trying on New Clothing with Arbitrary Poses](https://xuemengsong.github.io/fp452-zhengA.pdf)\n\n### 1.5 Fashion Editing\n\n* [Fashion++: Minimal Edits for Outfit Improvement](https://arxiv.org/abs/1904.09261)\n* [Fashion Editing with Multi-scale Attention Normalization](https://arxiv.org/abs/1906.00884)\n* [Fashion-AttGAN: Attribute-Aware Fashion Editing with Multi-Objective GAN](https://arxiv.org/abs/1904.07460)\n* [Compatible and Diverse Fashion Image Inpainting](https://arxiv.org/abs/1902.01096)\n\n### 1.6 3D Garment\n\n* [Deep Fashion3D: A Dataset and Benchmark for 3D Garment Reconstruction from Single Images](https://arxiv.org/pdf/2003.12753v1.pdf)\n\n### 1.7 Fit and Size Recommendation\n\n* [Decomposing Fit Semantics for Product Size Recommendation in Metric Spaces](http://cseweb.ucsd.edu/~jmcauley/pdfs/recsys18e.pdf)\n\n## 2. Workshop\n\n* [ICCV 2019 Second Workshop on Computer Vision for Fashion, Art and Design](https://sites.google.com/view/cvcreative/home?authuser=0)\n\n## 3. Datasets\n\n|    | Image | Text | Category  | Attribute | Landmark | Box | Mask | Relation | Other |\n|---|---|---|---|---|---|---|---|---|---|\n| [ACWS](https://data.vision.ee.ethz.ch/cvl/lbossard/accv12/) | :white_check_mark: |   | :white_check_mark: |   |   |   |   |   |   |\n| [Clothing1M](https://github.com/Cysu/noisy_label) | :white_check_mark: |   |   | :white_check_mark: |   |   |   |   |   |\n| [DCSA](http://chenlab.ece.cornell.edu/people/Andy/publications/ECCV2012_ClothingAttributes.pdf) | :white_check_mark: |   |   | :white_check_mark: |   |   |   |   |   |\n| [DeepFashion](http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html) | :white_check_mark: |   | :white_check_mark: | :white_check_mark: |   |   |   | street2shop  |   |\n| [DeepFashion2](https://github.com/switchablenorms/DeepFashion2) | :white_check_mark: |   | :white_check_mark: | :white_check_mark: |   |   | :white_check_mark: | street2shop  |   |\n| [imaterialist-2018](https://vision.cornell.edu/se3/wp-content/uploads/2019/06/1906.05750.pdf) | :white_check_mark: |   | :white_check_mark: | :white_check_mark: |   |   |   |   |   |\n| [imaterialist-2019](https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6) | :white_check_mark: |   | :white_check_mark: | :white_check_mark: |   |   | :white_check_mark: |   |   |\n| [WTBI](http://tamaraberg.com/street2shop/) | :white_check_mark: |   |   |   |   |   |   | street2shop |   |\n\n## 4. Company\n\n* [Chicisimo](https://hackernoon.com/how-we-grew-from-0-to-4-million-women-on-our-fashion-app-with-a-vertical-machine-learning-approach-f8b7fc0a89d7)\n* [infimind](https://www.infimind.com/#)\n\n## Similar Repository\n\n- [Cool Fashion Papers](https://github.com/lzhbrian/Cool-Fashion-Papers)\n- [awesome-fashion-ai](https://github.com/ayushidalmia/awesome-fashion-ai)\n","output":"/Users/wangx/Downloads/curated-fashion-ai/README.html"})</script>
</body>
</html>
